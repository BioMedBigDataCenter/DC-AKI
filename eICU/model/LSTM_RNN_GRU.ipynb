{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, recall_score, accuracy_score, auc, f1_score, matthews_corrcoef, precision_score, precision_recall_curve, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation, Dropout, Input, GRU\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.compat.v1.keras.layers import LSTM\n",
    "\n",
    "seed = 8888\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "to_save = {}\n",
    "to_save['random_seed'] = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 837\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_cutoff(TPRs, FPRs, thresholds):\n",
    "    \"\"\"\n",
    "    Find the optimal classification threshold, where the distance between TPR and FPR is maximum\n",
    "    :param TPRs: TPR values at different thresholds\n",
    "    :param FPRs: FPR values at different thresholds\n",
    "    :param thresholds: Different classification thresholds\n",
    "    :return: optimal classification threshold, (optimal TPR, optimal FPR)\n",
    "    \"\"\"\n",
    "    distance = TPRs - FPRs\n",
    "    idx = np.argmax(distance)  # Only the first occurrence is returned.\n",
    "    optimal_threshold = thresholds[idx]\n",
    "    optimal_point = (TPRs[idx], FPRs[idx])\n",
    "    \n",
    "    return optimal_threshold, optimal_point\n",
    "\n",
    "\n",
    "def roc_values(y_true, y_proba):\n",
    "    \"\"\"\n",
    "    Get FPRs, TPRs, AUC value, optimal classification threshold, optimal TPR and optimal FPR of ROC curve\n",
    "    :param y_true: True values list of sample labels\n",
    "    :param y_proba: Model-predicted probability of AKI\n",
    "    :return: FPRs, TPRs, AUC value, optimal classification threshold, (optimal TPR, optimal FPR)\n",
    "    \"\"\"\n",
    "    fprs, tprs, thresholds = roc_curve(y_true, y_proba, pos_label=1)\n",
    "    roc_auc = auc(fprs, tprs)\n",
    "    optimal_threshold, optimal_point = find_optimal_cutoff(TPRs=tprs, FPRs=fprs, thresholds=thresholds)\n",
    "    \n",
    "    return fprs, tprs, roc_auc, optimal_threshold, optimal_point\n",
    "\n",
    "\n",
    "def get_set(id_list, id_col, time_col, data):\n",
    "    \"\"\"\n",
    "    Get patient data for the specified ID list\n",
    "    :param id_col: Name of ID column\n",
    "    :param time_col: Name of timestamp column\n",
    "    :param data: DataFrame of patient data\n",
    "    :return: Patient data for the specified ID list\n",
    "    \"\"\"\n",
    "    data = data[data[id_col].isin(id_list)].sort_values(by=[id_col, time_col], ascending=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def performance(label, proba, pred):\n",
    "    \"\"\"\n",
    "    Get model evaluation metrics\n",
    "    :param label: True values list of sample labels\n",
    "    :param proba: Model-predicted probability of AKI\n",
    "    :param pred: Predicted values under the optimal classification threshold\n",
    "    :return: Accuracy, Recall, MCC, Precision, F1-score, AUC, FPR\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(label, pred)\n",
    "    recall = recall_score(label, pred, pos_label=1)\n",
    "    mcc = matthews_corrcoef(label, pred)\n",
    "    precision = precision_score(label, pred)\n",
    "    f1 = f1_score(label, pred)\n",
    "    roc_auc = roc_auc_score(label, proba)\n",
    "    tn, fp, fn, tp = confusion_matrix(label, pred).ravel()\n",
    "    fpr = fp/(fp+tn)\n",
    "    \n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'recall: {recall:.4f}')\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "    print(f'MCC: {mcc:.4f}')\n",
    "    print(f'precision: {precision:.4f}')\n",
    "    print(f'F1: {f1:.4f}')\n",
    "    print(f'FPR: {fpr:.4f}')\n",
    "    \n",
    "    return acc, recall, mcc, precision, f1, roc_auc, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "\n",
    "# Imputing(feature and label)\n",
    "FILL_WITH_ZERO = True\n",
    "FILL_VALUE = 0\n",
    "\n",
    "LABEL_COLUMN = 'aki_stage'\n",
    "# Resample interval\n",
    "RSMP = 6\n",
    "# Advance prediction time\n",
    "SFT = 48\n",
    "# FEATURE_SET = 'SCr_lab_vit_dem_med_pro'\n",
    "\n",
    "DATA_PATH = f'./data_con1_eICU0814.tsv'\n",
    "#DATA_PATH = f'./con0726/data_con_eICU0814.tsv'\n",
    "DATA_EXTERNAL_PATH = f'./data0727/data_external_rsmp{RSMP}.tsv'\n",
    "MODEL_SAVE_PATH = './GRU24.h5'\n",
    "TEST_RESULT_PATH = f'./predict_result/rsmp{RSMP}_sft{SFT}_continuous.csv'\n",
    "EXTERNAL_RESULT_PATH = f'./predict_result/rsmp{RSMP}_sft{SFT}_continuous_external.csv' \n",
    "TRAINING_PARAM_PATH = './result.xls'\n",
    "\n",
    "to_save['batch_size'] = BATCH_SIZE\n",
    "to_save['epoch'] = EPOCHS\n",
    "to_save['imputation'] = 'fill with zero'\n",
    "to_save['resample_interval'] = RSMP\n",
    "to_save['prediction_ahead'] = SFT\n",
    "to_save['data_dev_path'] = DATA_PATH\n",
    "to_save['data_external_path'] = DATA_EXTERNAL_PATH\n",
    "to_save['model_path'] = MODEL_SAVE_PATH\n",
    "to_save['test_result_path'] = TEST_RESULT_PATH\n",
    "to_save['external_result_path'] = EXTERNAL_RESULT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample num: 19799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(867140, 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori = pd.read_csv(DATA_PATH, sep='\\t')\n",
    "if 'patient_id' in data_ori.columns:\n",
    "    data_ori.rename(columns={'patient_id': 'stay_id', '检验日期': 'charttime'}, inplace=True)\n",
    "id_col, time_col = 'stay_id', 'charttime'\n",
    "print(f'Sample num: {data_ori.stay_id.nunique()}')\n",
    "data_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>akistage</th>\n",
       "      <th>index</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>sao2</th>\n",
       "      <th>ptt</th>\n",
       "      <th>pt</th>\n",
       "      <th>bun</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>unitadmitsource_Acute Care/Floor</th>\n",
       "      <th>unitadmitsource_Chest Pain Center</th>\n",
       "      <th>unitadmitsource_Direct Admit</th>\n",
       "      <th>unitadmitsource_Emergency Department</th>\n",
       "      <th>unitadmitsource_Floor</th>\n",
       "      <th>unitadmitsource_ICU</th>\n",
       "      <th>unitadmitsource_Observation</th>\n",
       "      <th>unitadmitsource_Other</th>\n",
       "      <th>unitadmitsource_Room</th>\n",
       "      <th>unitadmitsource_Step-Down Unit (SDU)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141244</td>\n",
       "      <td>0 days 01:26:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>965.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141244</td>\n",
       "      <td>0 days 01:28:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141244</td>\n",
       "      <td>0 days 01:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2565.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141244</td>\n",
       "      <td>0 days 01:32:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141244</td>\n",
       "      <td>0 days 01:34:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stay_id        charttime  akistage  index  heartrate    sao2  ptt  pt  bun  \\\n",
       "0   141244  0 days 01:26:00       0.0      0       99.0   965.0  NaN NaN  NaN   \n",
       "1   141244  0 days 01:28:00       0.0      1       95.0  2580.0  NaN NaN  NaN   \n",
       "2   141244  0 days 01:30:00       0.0      2       95.0  2565.0  NaN NaN  NaN   \n",
       "3   141244  0 days 01:32:00       0.0      3       98.0  2625.0  NaN NaN  NaN   \n",
       "4   141244  0 days 01:34:00       0.0      4       95.0  3380.0  NaN NaN  NaN   \n",
       "\n",
       "    age  ...  unitadmitsource_Acute Care/Floor  \\\n",
       "0  59.0  ...                               0.0   \n",
       "1  59.0  ...                               0.0   \n",
       "2  59.0  ...                               0.0   \n",
       "3  59.0  ...                               0.0   \n",
       "4  59.0  ...                               0.0   \n",
       "\n",
       "   unitadmitsource_Chest Pain Center  unitadmitsource_Direct Admit  \\\n",
       "0                                0.0                           0.0   \n",
       "1                                0.0                           0.0   \n",
       "2                                0.0                           0.0   \n",
       "3                                0.0                           0.0   \n",
       "4                                0.0                           0.0   \n",
       "\n",
       "   unitadmitsource_Emergency Department  unitadmitsource_Floor  \\\n",
       "0                                   0.0                    0.0   \n",
       "1                                   0.0                    0.0   \n",
       "2                                   0.0                    0.0   \n",
       "3                                   0.0                    0.0   \n",
       "4                                   0.0                    0.0   \n",
       "\n",
       "   unitadmitsource_ICU  unitadmitsource_Observation  unitadmitsource_Other  \\\n",
       "0                  0.0                          0.0                    0.0   \n",
       "1                  0.0                          0.0                    0.0   \n",
       "2                  0.0                          0.0                    0.0   \n",
       "3                  0.0                          0.0                    0.0   \n",
       "4                  0.0                          0.0                    0.0   \n",
       "\n",
       "   unitadmitsource_Room  unitadmitsource_Step-Down Unit (SDU)  \n",
       "0                   1.0                                   0.0  \n",
       "1                   1.0                                   0.0  \n",
       "2                   1.0                                   0.0  \n",
       "3                   1.0                                   0.0  \n",
       "4                   1.0                                   0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stay_id', 'charttime', 'akistage', 'index', 'heartrate', 'sao2', 'ptt',\n",
       "       'pt', 'bun', 'age', 'hospitaladmitoffset', 'gender_Female',\n",
       "       'gender_Male', 'gender_Unknown', 'ethnicity_',\n",
       "       'ethnicity_African American', 'ethnicity_Asian', 'ethnicity_Caucasian',\n",
       "       'ethnicity_Hispanic', 'ethnicity_Native American',\n",
       "       'ethnicity_Other/Unknown', 'unitadmitsource_', 'unitadmitsource_ACU',\n",
       "       'unitadmitsource_Acute Care/Floor', 'unitadmitsource_Chest Pain Center',\n",
       "       'unitadmitsource_Direct Admit', 'unitadmitsource_Emergency Department',\n",
       "       'unitadmitsource_Floor', 'unitadmitsource_ICU',\n",
       "       'unitadmitsource_Observation', 'unitadmitsource_Other',\n",
       "       'unitadmitsource_Room', 'unitadmitsource_Step-Down Unit (SDU)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ori = data_ori.rename(columns={'akistage': 'aki_stage'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "others = [id_col, time_col, LABEL_COLUMN]\n",
    "# common_feat = ['hemoglobin', 'chloride', 'sodium', 'potassium', 'creatinine', 'admission_age', 'gender_F', 'gender_M']\n",
    "# data_ori = data_ori[['icustay_id', 'charttime', 'aki_stage']+common_feat].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_num: 17482\n",
      "AKI_label: [0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(715739, 33)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_ori.copy()\n",
    "# Label imputing\n",
    "data[LABEL_COLUMN].fillna(FILL_VALUE, inplace=True)\n",
    "data[LABEL_COLUMN] = data.groupby(id_col)[LABEL_COLUMN].shift(-(SFT/RSMP))\n",
    "data.dropna(subset=[LABEL_COLUMN], how='all', inplace=True)\n",
    "data[LABEL_COLUMN].replace([2, 3], [1, 1], inplace=True)\n",
    "    \n",
    "print(f'Sample_num: {data[id_col].nunique()}')\n",
    "print(f'AKI_label: {data[LABEL_COLUMN].unique()}')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = data[data['aki_stage'] == 1]\n",
    "negative_samples = data[data['aki_stage'] == 0]\n",
    "\n",
    "# 欠采样，从akistage为0的数据中随机选择样本\n",
    "undersampled_negative = negative_samples.sample(n=100, replace=False, random_state=42)\n",
    "undersampled_data = pd.concat([positive_samples, undersampled_negative], axis=0)\n",
    "\n",
    "# 打乱数据，确保随机性\n",
    "undersampled = undersampled_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "data = undersampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签数量统计: Counter({0.0: 99, 1.0: 38})\n",
      "AKI病人占比: 0.2774\n"
     ]
    }
   ],
   "source": [
    "aki = data[[id_col, LABEL_COLUMN]].copy()\n",
    "aki = aki.groupby([id_col]).max()\n",
    "c = Counter(aki[LABEL_COLUMN].values)\n",
    "print(f'标签数量统计: {c}')\n",
    "print(f'AKI病人占比: {c[1]/len(aki):.4f}')\n",
    "to_save['AKI_ratio'] = c[1]/len(aki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.charttime = pd.to_datetime(data.charttime)\n",
    "data.sort_values(by=[id_col, time_col], ascending=True, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_order = [col for col in data.columns if col != 'aki_stage'] + ['aki_stage']\n",
    "data = data[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stay_id', 'charttime', 'index', 'heartrate', 'sao2', 'ptt', 'pt', 'bun', 'age', 'hospitaladmitoffset', 'gender_Female', 'gender_Male', 'gender_Unknown', 'ethnicity_', 'ethnicity_African American', 'ethnicity_Asian', 'ethnicity_Caucasian', 'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown', 'unitadmitsource_', 'unitadmitsource_ACU', 'unitadmitsource_Acute Care/Floor', 'unitadmitsource_Chest Pain Center', 'unitadmitsource_Direct Admit', 'unitadmitsource_Emergency Department', 'unitadmitsource_Floor', 'unitadmitsource_ICU', 'unitadmitsource_Observation', 'unitadmitsource_Other', 'unitadmitsource_Room', 'unitadmitsource_Step-Down Unit (SDU)', 'aki_stage']\n"
     ]
    }
   ],
   "source": [
    "column_order = data.columns.tolist()\n",
    "print(column_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.drop(columns=['hospitaladmitoffset','index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample num: 137, Feature num: 28\n",
      "\n",
      "features: ['age', 'bun', 'ethnicity_', 'ethnicity_African American', 'ethnicity_Asian', 'ethnicity_Caucasian', 'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown', 'gender_Female', 'gender_Male', 'gender_Unknown', 'heartrate', 'pt', 'ptt', 'sao2', 'unitadmitsource_', 'unitadmitsource_ACU', 'unitadmitsource_Acute Care/Floor', 'unitadmitsource_Chest Pain Center', 'unitadmitsource_Direct Admit', 'unitadmitsource_Emergency Department', 'unitadmitsource_Floor', 'unitadmitsource_ICU', 'unitadmitsource_Observation', 'unitadmitsource_Other', 'unitadmitsource_Room', 'unitadmitsource_Step-Down Unit (SDU)']\n"
     ]
    }
   ],
   "source": [
    "icustays = data.stay_id.unique().tolist()\n",
    "features = data.columns.difference(others).tolist()\n",
    "\n",
    "print(f'Sample num: {len(icustays)}, Feature num: {len(features)}\\n')\n",
    "print(f'features: {features}')\n",
    "\n",
    "to_save['sample_num'] = len(icustays)\n",
    "to_save['feature_num'] = len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['index', 'hospitaladmitoffset']\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "features.remove('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新特征列表\n",
    "features.remove('hospitaladmitoffset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stay_id', 'charttime', 'heartrate', 'sao2', 'ptt', 'pt', 'bun', 'age',\n",
       "       'gender_Female', 'gender_Male', 'gender_Unknown', 'ethnicity_',\n",
       "       'ethnicity_African American', 'ethnicity_Asian', 'ethnicity_Caucasian',\n",
       "       'ethnicity_Hispanic', 'ethnicity_Native American',\n",
       "       'ethnicity_Other/Unknown', 'unitadmitsource_', 'unitadmitsource_ACU',\n",
       "       'unitadmitsource_Acute Care/Floor', 'unitadmitsource_Chest Pain Center',\n",
       "       'unitadmitsource_Direct Admit', 'unitadmitsource_Emergency Department',\n",
       "       'unitadmitsource_Floor', 'unitadmitsource_ICU',\n",
       "       'unitadmitsource_Observation', 'unitadmitsource_Other',\n",
       "       'unitadmitsource_Room', 'unitadmitsource_Step-Down Unit (SDU)',\n",
       "       'aki_stage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 838\n"
     ]
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>sao2</th>\n",
       "      <th>ptt</th>\n",
       "      <th>pt</th>\n",
       "      <th>bun</th>\n",
       "      <th>age</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>...</th>\n",
       "      <th>unitadmitsource_Chest Pain Center</th>\n",
       "      <th>unitadmitsource_Direct Admit</th>\n",
       "      <th>unitadmitsource_Emergency Department</th>\n",
       "      <th>unitadmitsource_Floor</th>\n",
       "      <th>unitadmitsource_ICU</th>\n",
       "      <th>unitadmitsource_Observation</th>\n",
       "      <th>unitadmitsource_Other</th>\n",
       "      <th>unitadmitsource_Room</th>\n",
       "      <th>unitadmitsource_Step-Down Unit (SDU)</th>\n",
       "      <th>aki_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153993</td>\n",
       "      <td>0 days 02:02:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162778</td>\n",
       "      <td>0 days 01:46:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181698</td>\n",
       "      <td>13 days 12:11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183795</td>\n",
       "      <td>0 days 01:00:00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188576</td>\n",
       "      <td>0 days 01:11:00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stay_id         charttime  heartrate    sao2   ptt  pt  bun   age  \\\n",
       "0   153993   0 days 02:02:00       98.0   916.0   NaN NaN  NaN  59.0   \n",
       "1   162778   0 days 01:46:00      100.0  2898.0   NaN NaN  NaN  59.0   \n",
       "2   181698  13 days 12:11:00        NaN     NaN  59.0 NaN  NaN  60.0   \n",
       "3   183795   0 days 01:00:00       96.0   182.0   NaN NaN  NaN  72.0   \n",
       "4   188576   0 days 01:11:00       96.0   119.0   NaN NaN  NaN  89.0   \n",
       "\n",
       "   gender_Female  gender_Male  ...  unitadmitsource_Chest Pain Center  \\\n",
       "0            1.0          0.0  ...                                0.0   \n",
       "1            1.0          0.0  ...                                0.0   \n",
       "2            0.0          1.0  ...                                0.0   \n",
       "3            1.0          0.0  ...                                0.0   \n",
       "4            0.0          1.0  ...                                0.0   \n",
       "\n",
       "   unitadmitsource_Direct Admit  unitadmitsource_Emergency Department  \\\n",
       "0                           0.0                                   0.0   \n",
       "1                           0.0                                   0.0   \n",
       "2                           0.0                                   0.0   \n",
       "3                           0.0                                   0.0   \n",
       "4                           0.0                                   0.0   \n",
       "\n",
       "   unitadmitsource_Floor  unitadmitsource_ICU  unitadmitsource_Observation  \\\n",
       "0                    1.0                  0.0                          0.0   \n",
       "1                    1.0                  0.0                          0.0   \n",
       "2                    0.0                  0.0                          0.0   \n",
       "3                    0.0                  0.0                          0.0   \n",
       "4                    1.0                  0.0                          0.0   \n",
       "\n",
       "   unitadmitsource_Other  unitadmitsource_Room  \\\n",
       "0                    0.0                   0.0   \n",
       "1                    0.0                   0.0   \n",
       "2                    0.0                   1.0   \n",
       "3                    0.0                   1.0   \n",
       "4                    0.0                   0.0   \n",
       "\n",
       "   unitadmitsource_Step-Down Unit (SDU)  aki_stage  \n",
       "0                                   0.0        0.0  \n",
       "1                                   0.0        0.0  \n",
       "2                                   0.0        0.0  \n",
       "3                                   0.0        0.0  \n",
       "4                                   0.0        0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing with zero!\n"
     ]
    }
   ],
   "source": [
    "print('Imputing with zero!')\n",
    "data.fillna(FILL_VALUE, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 109\n",
      "Validation samples: 14\n",
      "Test samples: 14\n"
     ]
    }
   ],
   "source": [
    "train_id, val_test_id = train_test_split(icustays, test_size=0.2, random_state=seed)\n",
    "val_id, test_id = train_test_split(val_test_id, test_size=0.5, random_state=seed)\n",
    "print(f'Train samples: {len(train_id)}\\nValidation samples: {len(val_id)}\\nTest samples: {len(test_id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((110, 31), (14, 31), (14, 31))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_set(id_list=train_id, id_col=id_col, time_col=time_col, data=data)\n",
    "val = get_set(val_id, id_col, time_col, data)\n",
    "test = get_set(test_id, id_col, time_col, data)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.2844\n",
      "val: 0.2857\n",
      "test: 0.2143\n"
     ]
    }
   ],
   "source": [
    "# 各集合中AKI病人占比\n",
    "aki_train = train[[id_col, LABEL_COLUMN]].copy().groupby([id_col]).max()\n",
    "aki_val = val[[id_col, LABEL_COLUMN]].copy().groupby([id_col]).max()\n",
    "aki_test = test[[id_col, LABEL_COLUMN]].copy().groupby([id_col]).max()\n",
    "\n",
    "print(f'train: {aki_train.aki_stage.sum()/len(aki_train):.4f}')\n",
    "print(f'val: {aki_val.aki_stage.sum()/len(aki_val):.4f}')      \n",
    "print(f'test: {aki_test.aki_stage.sum()/len(aki_test):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split features and label / Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(by=[id_col, time_col], ascending=True, inplace=True)\n",
    "val.sort_values(by=[id_col, time_col], ascending=True, inplace=True)\n",
    "test.sort_values(by=[id_col, time_col], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[others+features].copy()\n",
    "val = val[others+features].copy()\n",
    "test = test[others+features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [train[train[id_col]==i].iloc[:, 2:].values for i in train_id]\n",
    "val_list = [val[val[id_col]==i].iloc[:, 2:].values for i in val_id]\n",
    "test_list = [test[test[id_col]==i].iloc[:, 2:].values for i in test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将训练集中最长的时间序列长度设置为模型最长时间步\n",
    "maxlen = train.groupby('stay_id').size().max()\n",
    "to_save['time_seq_length'] = maxlen\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((109, 2, 29), (14, 2, 29), (14, 2, 29))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pad_sequences(\n",
    "    train_list, \n",
    "    dtype='float32', \n",
    "    padding='pre', \n",
    "    truncating='pre', \n",
    "    value=0, \n",
    "    maxlen=maxlen\n",
    ")\n",
    "val_data = pad_sequences(\n",
    "    val_list, \n",
    "    dtype='float32', \n",
    "    padding='pre', \n",
    "    truncating='pre', \n",
    "    value=0, \n",
    "    maxlen=maxlen\n",
    ")\n",
    "test_data = pad_sequences(\n",
    "    test_list, \n",
    "    dtype='float32', \n",
    "    padding='pre', \n",
    "    truncating='pre', \n",
    "    value=0, \n",
    "    maxlen=maxlen\n",
    ")\n",
    "train_data.shape, val_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将特征和标签分离\n",
    "train_label = train_data[:, :, 0]\n",
    "val_label = val_data[:, :, 0]\n",
    "test_label = test_data[:, :, 0]\n",
    "\n",
    "train_data = train_data[:, :, 1:]\n",
    "val_data = val_data[:, :, 1:]\n",
    "test_data = test_data[:, :, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((109, 2, 28), (14, 2, 28), (14, 2, 28))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature normalization\n",
    "train_data = train_data.reshape(-1, len(features))\n",
    "val_data = val_data.reshape(-1, len(features))\n",
    "test_data = test_data.reshape(-1, len(features))\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "feature_scaler.fit(train_data)\n",
    "\n",
    "train_data = feature_scaler.transform(train_data)\n",
    "train_data = train_data.reshape(-1, maxlen, len(features))\n",
    "\n",
    "val_data = feature_scaler.transform(val_data)\n",
    "val_data = val_data.reshape(-1, maxlen, len(features))\n",
    "\n",
    "test_data = feature_scaler.transform(test_data)\n",
    "test_data = test_data.reshape(-1, maxlen, len(features))\n",
    "\n",
    "train_data.shape, val_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((109, 2, 2), (14, 2, 2), (14, 2, 2))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label one-hot\n",
    "train_label = train_label.reshape(-1, maxlen, 1)\n",
    "val_label = val_label.reshape(-1, maxlen, 1)\n",
    "test_label = test_label.reshape(-1, maxlen, 1)\n",
    "\n",
    "train_label = to_categorical(train_label)\n",
    "val_label = to_categorical(val_label)\n",
    "test_label = to_categorical(test_label)\n",
    "\n",
    "train_label.shape, val_label.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, GRU, Bidirectional, Dense, Dropout, Attention\n",
    "def get_model(max_len, feature_num):\n",
    "    \n",
    "    clear_session()\n",
    "    inputs = Input(shape=(max_len, feature_num), dtype='float32')\n",
    "    x = Dense(64, activation='relu')(inputs)\n",
    "    x = LSTM(32, return_sequences=True,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = LSTM(32, return_sequences=True,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = LSTM(32, return_sequences=True,activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    outputs = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2, 28)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2, 64)             1856      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 2, 32)             12416     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 2, 32)             8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 2, 32)             8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2, 32)             1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2, 2)              66        \n",
      "=================================================================\n",
      "Total params: 32,034\n",
      "Trainable params: 32,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_LSTM = get_model(max_len=maxlen, feature_num=len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.001)\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "k_auc = AUC()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODEL_SAVE_PATH, \n",
    "    monitor='val_auc', \n",
    "    mode='max', \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model_LSTM.compile(\n",
    "    optimizer=adam, \n",
    "    loss=loss,\n",
    "    metrics=[k_auc]\n",
    ")\n",
    "\n",
    "to_save['lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 109 samples, validate on 14 samples\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 5s 43ms/sample - loss: 0.6889 - auc: 0.7748 - val_loss: 0.6824 - val_auc: 0.8469\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 926us/sample - loss: 0.6769 - auc: 0.8325 - val_loss: 0.6696 - val_auc: 0.8469\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 989us/sample - loss: 0.6627 - auc: 0.8193 - val_loss: 0.6542 - val_auc: 0.7908\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 814us/sample - loss: 0.6447 - auc: 0.8131 - val_loss: 0.6345 - val_auc: 0.7883\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 796us/sample - loss: 0.6215 - auc: 0.7939 - val_loss: 0.6066 - val_auc: 0.7844\n",
      "12.261983\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "history = model_LSTM.fit(\n",
    "    train_data, train_label,\n",
    "    validation_data=(val_data, val_label), \n",
    "    batch_size=16, \n",
    "    epochs=5, \n",
    "    callbacks=[checkpoint])\n",
    "train_time = (datetime.now() - time_start).total_seconds()\n",
    "to_save['train_time'] = train_time\n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_LSTM = model_LSTM.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 2, 2), (14, 2, 2))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_LSTM.shape,test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label=test_label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8431122448979592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 将三维数组转换为一维数组\n",
    "reshaped_test_LSTM = test_LSTM.flatten()\n",
    "reshaped_true_label = true_label.flatten()\n",
    "\n",
    "# 计算 ROC AUC\n",
    "roc_auc_LSTM = roc_auc_score(reshaped_true_label, reshaped_test_LSTM)\n",
    "print(f\"ROC AUC: {roc_auc_LSTM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.805827989143032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc,f1_score\n",
    "precision_LSTM, recall_LSTM, thresholds_LSTM = precision_recall_curve(reshaped_true_label, reshaped_test_LSTM)\n",
    "# 计算 PR AUC\n",
    "pr_auc_LSTM = auc(recall_LSTM, precision_LSTM)\n",
    "\n",
    "\n",
    "print(\"PR AUC:\", pr_auc_LSTM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8928571428571429\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 821\n"
     ]
    }
   ],
   "source": [
    "fpr_LSTM, tpr_LSTM, thresholds_LSTM = roc_curve(reshaped_true_label, reshaped_test_LSTM, drop_intermediate=False)\n",
    "roc_auc_LSTM = auc(fpr_LSTM, tpr_LSTM)\n",
    "print(roc_auc_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 818\n"
     ]
    }
   ],
   "source": [
    "true_test = test_LSTM.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "newarr = test_LSTM.reshape(28,2)\n",
    "newarr_label = test_label.reshape(28,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 2), (28, 2))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newarr.shape,newarr_label.shape,newarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "reshaped_test_LSTM = (reshaped_test_LSTM > threshold).astype(int)\n",
    "f1 = f1_score(reshaped_true_label, reshaped_test_LSTM)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label=test_label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.to_csv(TEST_RESULT_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC-AKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'our08151.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 839\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, Conv1D, MaxPooling1D, GRU, Bidirectional, Dense, Dropout, Concatenate, Activation, GlobalMaxPooling1D, Multiply, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "def get_model(max_len, feature_num):\n",
    "    x = Input(shape=(max_len, feature_num), dtype='float32')\n",
    "    x1 = Dense(64, activation='relu')(x)\n",
    "    x1 = GRU(32, return_sequences=True)(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    x1 = GRU(32, return_sequences=True)(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    attention = Dense(32, activation='tanh')(x1)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('sigmoid')(attention)\n",
    "    attention_reshaped = Reshape((max_len, 32))(attention)\n",
    "    \n",
    "    # Multiply and Add layers for element-wise multiplication and addition\n",
    "    attention_mult = Multiply()([x1, attention_reshaped])\n",
    "    attention_sum = Add()([x1, attention_reshaped])\n",
    "    \n",
    "    y2 = Dense(64, activation='relu')(x)\n",
    "    y2 = Conv1D(filters=128, kernel_size=3, padding='same')(y2)\n",
    "    y2 = Dropout(0.5)(y2)\n",
    "    #y2 = GlobalMaxPooling1D()(y2)\n",
    "    y2 = Dense(64, activation='relu')(y2)\n",
    "    concatenated = Concatenate()([attention_mult, attention_sum, y2])\n",
    "    concatenated = Dense(32, activation='relu')(concatenated)\n",
    "    outputs = Dense(2, activation='sigmoid')(concatenated)\n",
    "    \n",
    "    model = Model(inputs=x, outputs=outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2, 28)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2, 64)        1856        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 2, 32)        9312        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2, 32)        0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 2, 32)        6240        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 32)        0           gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2, 32)        1056        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2, 64)        1856        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64)           0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 2, 128)       24704       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 2, 32)        0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2, 128)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 2, 32)        0           dropout_1[0][0]                  \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2, 32)        0           dropout_1[0][0]                  \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2, 64)        8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2, 128)       0           multiply[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2, 32)        4128        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2, 2)         66          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,474\n",
      "Trainable params: 57,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_our = get_model(max_len=maxlen, feature_num=len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.001)\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "k_auc = AUC()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODEL_SAVE_PATH, \n",
    "    monitor='val_auc', \n",
    "    mode='max', \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model_our.compile(\n",
    "    optimizer=adam, \n",
    "    loss=loss,\n",
    "    metrics=[k_auc]\n",
    ")\n",
    "\n",
    "to_save['lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 109 samples, validate on 14 samples\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 7s 68ms/sample - loss: 0.5883 - auc: 0.8464 - val_loss: 0.4693 - val_auc: 0.8986\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 2ms/sample - loss: 0.4005 - auc: 0.9163 - val_loss: 0.3563 - val_auc: 0.9343\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 2ms/sample - loss: 0.3311 - auc: 0.9392 - val_loss: 0.3129 - val_auc: 0.9445\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 2ms/sample - loss: 0.2968 - auc: 0.9519 - val_loss: 0.2859 - val_auc: 0.9483\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 2ms/sample - loss: 0.2736 - auc: 0.9531 - val_loss: 0.2718 - val_auc: 0.9522\n",
      "14.845942\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "history = model_our.fit(\n",
    "    train_data, train_label,\n",
    "    validation_data=(val_data, val_label), \n",
    "    batch_size=16, \n",
    "    epochs=5, \n",
    "    callbacks=[checkpoint])\n",
    "train_time = (datetime.now() - time_start).total_seconds()\n",
    "to_save['train_time'] = train_time\n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./GRU24.h5\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9604591836734694\n"
     ]
    }
   ],
   "source": [
    "test_our = model_our.predict(test_data)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 将三维数组转换为一维数组\n",
    "reshaped_test_our = test_our.flatten()\n",
    "reshaped_true_label = test_label.flatten()\n",
    "\n",
    "# 计算 ROC AUC\n",
    "roc_auc_our = roc_auc_score(reshaped_true_label, reshaped_test_our)\n",
    "print(f\"ROC AUC: {roc_auc_our}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9604591836734694\n"
     ]
    }
   ],
   "source": [
    "fpr_our, tpr_our, thresholds_our = roc_curve(reshaped_true_label, reshaped_test_our)\n",
    "roc_auc_our = auc(fpr_our, tpr_our)\n",
    "print(roc_auc_our)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9604591836734694\n"
     ]
    }
   ],
   "source": [
    "roc_auc_our = roc_auc_score(reshaped_true_label, reshaped_test_our)\n",
    "print(f\"ROC AUC: {roc_auc_our}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.9623602039462463\n",
      "0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc,f1_score\n",
    "precision_our, recall_our, thresholds = precision_recall_curve(reshaped_true_label, reshaped_test_our)\n",
    "# 计算 PR AUC\n",
    "pr_auc_our= auc(recall_our, precision_our)\n",
    "print(\"PR AUC:\", pr_auc_our)\n",
    "threshold = 0.5\n",
    "reshaped_test_our = (reshaped_test_our > threshold).astype(int)\n",
    "f1 = f1_score(reshaped_true_label, reshaped_test_our)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, GRU, Bidirectional, Dense, Dropout, Attention,SimpleRNN\n",
    "def get_model(max_len, feature_num):\n",
    "    \n",
    "    clear_session()\n",
    "    inputs = Input(shape=(max_len, feature_num), dtype='float32')\n",
    "    x = Dense(64, activation='relu')(inputs)\n",
    "    x = SimpleRNN(128, return_sequences=True,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = SimpleRNN(128, return_sequences=True,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = SimpleRNN(128, return_sequences=True,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2, 28)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2, 64)             1856      \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 2, 128)            24704     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 2, 128)            32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 2, 128)            32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2, 2)              258       \n",
      "=================================================================\n",
      "Total params: 92,610\n",
      "Trainable params: 92,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_RNN = get_model(max_len=maxlen, feature_num=len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.001)\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "k_auc = AUC()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODEL_SAVE_PATH, \n",
    "    monitor='val_auc', \n",
    "    mode='max', \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model_RNN.compile(\n",
    "    optimizer=adam, \n",
    "    loss=loss,\n",
    "    metrics=[k_auc]\n",
    ")\n",
    "\n",
    "to_save['lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 109 samples, validate on 14 samples\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 2s 18ms/sample - loss: 0.6518 - auc: 0.6834 - val_loss: 0.5813 - val_auc: 0.7876\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 1ms/sample - loss: 0.5480 - auc: 0.8306 - val_loss: 0.5129 - val_auc: 0.8010\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 1ms/sample - loss: 0.4807 - auc: 0.8524 - val_loss: 0.4561 - val_auc: 0.8578\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 1ms/sample - loss: 0.4211 - auc: 0.8842 - val_loss: 0.3868 - val_auc: 0.9094\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 2ms/sample - loss: 0.3650 - auc: 0.9206 - val_loss: 0.3381 - val_auc: 0.9503\n",
      "5.326135\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "history = model_RNN.fit(\n",
    "    train_data, train_label,\n",
    "    validation_data=(val_data, val_label), \n",
    "    batch_size=16, \n",
    "    epochs=5, \n",
    "    callbacks=[checkpoint])\n",
    "train_time = (datetime.now() - time_start).total_seconds()\n",
    "to_save['train_time'] = train_time\n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9413265306122449\n"
     ]
    }
   ],
   "source": [
    "test_RNN = model_RNN.predict(test_data)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 将三维数组转换为一维数组\n",
    "reshaped_test_RNN = test_RNN.flatten()\n",
    "#reshaped_true_label = true_label.flatten()\n",
    "\n",
    "# 计算 ROC AUC\n",
    "roc_auc_RNN = roc_auc_score(reshaped_true_label, reshaped_test_RNN)\n",
    "print(f\"ROC AUC: {roc_auc_RNN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9413265306122449\n"
     ]
    }
   ],
   "source": [
    "fpr_RNN, tpr_RNN, thresholds_our = roc_curve(reshaped_true_label, reshaped_test_RNN)\n",
    "roc_auc_RNN = auc(fpr_RNN, tpr_RNN)\n",
    "print(roc_auc_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.9441406280242418\n",
      "0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc,f1_score\n",
    "precision_RNN, recall_RNN, thresholds = precision_recall_curve(reshaped_true_label, reshaped_test_RNN)\n",
    "# 计算 PR AUC\n",
    "pr_auc_RNN= auc(recall_RNN, precision_RNN)\n",
    "\n",
    "\n",
    "print(\"PR AUC:\", pr_auc_RNN)\n",
    "threshold = 0.5\n",
    "reshaped_test_RNN = (reshaped_test_RNN > threshold).astype(int)\n",
    "f1 = f1_score(reshaped_true_label, reshaped_test_RNN)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, GRU, Bidirectional, Dense, Dropout, Attention\n",
    "def get_model(max_len, feature_num):\n",
    "    \n",
    "    clear_session()\n",
    "    inputs = Input(shape=(max_len, feature_num), dtype='float32')\n",
    "    x = Dense(64, activation='relu')(inputs)\n",
    "    x = GRU(64, return_sequences=True,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = GRU(64, return_sequences=True,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = GRU(64, return_sequences=True,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2, 28)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2, 64)             1856      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 2, 64)             24768     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 2, 64)             24768     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 2, 64)             24768     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2, 64)             4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2, 2)              130       \n",
      "=================================================================\n",
      "Total params: 80,450\n",
      "Trainable params: 80,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_GRU = get_model(max_len=maxlen, feature_num=len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.001)\n",
    "loss = BinaryCrossentropy(from_logits=False)\n",
    "k_auc = AUC()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    MODEL_SAVE_PATH, \n",
    "    monitor='val_auc', \n",
    "    mode='max', \n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model_GRU.compile(\n",
    "    optimizer=adam, \n",
    "    loss=loss,\n",
    "    metrics=[k_auc]\n",
    ")\n",
    "\n",
    "to_save['lr'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 109 samples, validate on 14 samples\n",
      "Epoch 1/5\n",
      "109/109 [==============================] - 5s 46ms/sample - loss: 0.6912 - auc: 0.6464 - val_loss: 0.6816 - val_auc: 0.8291\n",
      "Epoch 2/5\n",
      "109/109 [==============================] - 0s 975us/sample - loss: 0.6742 - auc: 0.8511 - val_loss: 0.6639 - val_auc: 0.7857\n",
      "Epoch 3/5\n",
      "109/109 [==============================] - 0s 918us/sample - loss: 0.6521 - auc: 0.8325 - val_loss: 0.6386 - val_auc: 0.7819\n",
      "Epoch 4/5\n",
      "109/109 [==============================] - 0s 852us/sample - loss: 0.6208 - auc: 0.8301 - val_loss: 0.5986 - val_auc: 0.7825\n",
      "Epoch 5/5\n",
      "109/109 [==============================] - 0s 841us/sample - loss: 0.5670 - auc: 0.8198 - val_loss: 0.5445 - val_auc: 0.7806\n",
      "11.217302\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "history = model_GRU.fit(\n",
    "    train_data, train_label,\n",
    "    validation_data=(val_data, val_label), \n",
    "    batch_size=16, \n",
    "    epochs=5, \n",
    "    callbacks=[checkpoint])\n",
    "train_time = (datetime.now() - time_start).total_seconds()\n",
    "to_save['train_time'] = train_time\n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8380102040816326\n"
     ]
    }
   ],
   "source": [
    "test_GRU = model_GRU.predict(test_data)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 将三维数组转换为一维数组\n",
    "reshaped_test_GRU = test_GRU.flatten()\n",
    "#reshaped_true_label = true_label.flatten()\n",
    "\n",
    "# 计算 ROC AUC\n",
    "roc_auc_GRU = roc_auc_score(reshaped_true_label, reshaped_test_GRU)\n",
    "print(f\"ROC AUC: {roc_auc_GRU}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8380102040816326\n"
     ]
    }
   ],
   "source": [
    "fpr_GRU, tpr_GRU, thresholds_GRU = roc_curve(reshaped_true_label, reshaped_test_GRU)\n",
    "roc_auc_GRU = auc(fpr_GRU, tpr_GRU)\n",
    "print(roc_auc_GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR AUC: 0.78685834622901\n",
      "0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc,f1_score\n",
    "precision_GRU, recall_GRU, thresholds = precision_recall_curve(reshaped_true_label, reshaped_test_GRU)\n",
    "# 计算 PR AUC\n",
    "pr_auc_GRU= auc(recall_GRU, precision_GRU)\n",
    "\n",
    "\n",
    "print(\"PR AUC:\", pr_auc_GRU)\n",
    "threshold = 0.5\n",
    "reshaped_test_GRU = (reshaped_test_GRU > threshold).astype(int)\n",
    "f1 = f1_score(reshaped_true_label, reshaped_test_GRU)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
